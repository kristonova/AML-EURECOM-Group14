{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef7886e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook delivers a fully reproducible workflow for the Slide‑Rail Acoustic‑Anomaly Detection laboratory exercise described in the AML 2025 challenge PDF. Leveraging reference implementations from the public repositories `wilkinghoff/DCASE2023_task2` and `DCASE-REPO`, it demonstrates data preparation, model training, and evaluation in a structured manner. Each subsequent section begins with a concise, three‑sentence academic exposition to clarify its methodological role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fefff",
   "metadata": {},
   "source": [
    "## Environment & Dependency Setup\n",
    "This section installs the minimal set of Python libraries required for signal processing, model construction, and evaluation, ensuring version consistency with the reference GitHub repositories. Reproducibility is promoted by pinning the versions of core packages such as Librosa and PyTorch. If the environment already satisfies these dependencies, the installation commands can be safely skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4168d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet librosa==0.10.1 torch torchvision torchaudio scikit-learn tqdm nflows==0.15.0\n",
    "import warnings, random, zipfile, subprocess, os, math, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import metrics, mixture\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(42); np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ee4d3",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "Following the DCASE Task 2 protocol, the Slide‑Rail subset is retrieved from the course‑provided Kaggle dataset to guarantee alignment with the official evaluation setup. The download routine is guarded by a boolean flag to prevent redundant transfers for users who already have the data locally. All subsequent file paths are expressed relative to a configurable `DATA_DIR` variable to facilitate execution on heterogeneous platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acf481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory ready: /Users/mymac/Study Abroad/Master Computer Science EURECOM/AML/Lab/AML-EURECOM-Group14/Challenge 2-Anomaly Detection/dataset/dev_data/dev_data/slider\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_DATA = False  # toggle to True on first run\n",
    "DATA_DIR = Path('./dataset/dev_data/dev_data/slider')\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if DOWNLOAD_DATA:\n",
    "    kaggle_zip = 'dcase-aml-slide-rail.zip'  # replace with actual filename on Kaggle\n",
    "    if not (RAW_DIR / kaggle_zip).exists():\n",
    "        subprocess.run(['kaggle', 'datasets', 'download', '-d', 'michiard/dcase-aml', '-p', str(RAW_DIR)])\n",
    "    with zipfile.ZipFile(RAW_DIR / kaggle_zip) as zf:\n",
    "        zf.extractall(RAW_DIR)\n",
    "print('Data directory ready:', DATA_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6b1ad",
   "metadata": {},
   "source": [
    "## Acoustic Feature Extraction\n",
    "Log‑Mel spectrograms are selected as the principal time–frequency representation owing to their perceptual relevance and widespread adoption in anomaly detection literature. A helper function converts raw waveforms into logarithmic Mel matrices, caching results on disk to expedite iterative experimentation. Parameters adhere to the official DCASE baselines (16 kHz sampling, 64 Mel bins) to assure comparability with benchmark studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4013cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "N_FFT, HOP, N_MELS = 1024, 512, 64\n",
    "\n",
    "def extract_logmel(path, cache_dir=DATA_DIR / 'features'):\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cache = cache_dir / f'{path.stem}.npy'\n",
    "    if cache.exists():\n",
    "        return np.load(cache)\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP, n_mels=N_MELS, power=2\n",
    "    )\n",
    "    logmel = librosa.power_to_db(mel).astype(np.float32)\n",
    "    np.save(cache, logmel)\n",
    "    return logmel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a6e9a",
   "metadata": {},
   "source": [
    "## PyTorch Dataset Wrapper\n",
    "To streamline loading and batching, the `SlideRailDataset` class encapsulates on‑demand feature extraction with optional augmentation hooks. Following the one‑class paradigm, only recordings labelled as normal are passed to the training split, while a held‑out subset is reserved for validation. This explicit separation mitigates information leakage and supports robust early‑stopping strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82ed4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideRailDataset(Dataset):\n",
    "    def __init__(self, files, transform=None):\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self, idx):\n",
    "        feat = extract_logmel(self.files[idx])\n",
    "        if self.transform:\n",
    "            feat = self.transform(feat)\n",
    "        return torch.from_numpy(feat).unsqueeze(0)  # shape 1×M×T\n",
    "\n",
    "# Replace the glob patterns with actual sub‑directory names in your dataset\n",
    "train_files = sorted((DATA_DIR/'train').rglob('*.wav'))\n",
    "val_files   = train_files[::10]\n",
    "train_files = [f for f in train_files if f not in val_files]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d7ba7",
   "metadata": {},
   "source": [
    "## Convolutional Auto‑Encoder (CAE) Baseline\n",
    "A lightweight CAE serves as the foundational reconstruction‑based anomaly detector, optimising mean‑squared error on normal recordings. Its convolutional encoder–decoder architecture exploits local spectral correlations while keeping parameter count modest. The validation reconstruction error distribution establishes a first‑order anomaly threshold and baseline AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0502139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(), nn.Linear(64, latent_dim)\n",
    "        )\n",
    "        self.dec_fc = nn.Linear(latent_dim, 64)\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)\n",
    "        z = self.dec_fc(z).view(-1, 64, 1, 1)\n",
    "        return self.dec(z)\n",
    "\n",
    "def cae_loss(model, x):\n",
    "    recon = model(x)\n",
    "    # adapt x to the shape of recon using adaptive average pooling\n",
    "    x_resized = nn.functional.adaptive_avg_pool2d(x, recon.shape[2:])\n",
    "    return recon, nn.functional.mse_loss(recon, x_resized)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cae = CAE().to(device)\n",
    "train_loader = DataLoader(SlideRailDataset(train_files), batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(SlideRailDataset(val_files),   batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b50c1516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | Train 134.8014 | Val 6.4548\n",
      "Epoch  1 | Train 5.6580 | Val 6.1403\n",
      "Epoch  1 | Train 5.6580 | Val 6.1403\n",
      "Epoch  2 | Train 5.3900 | Val 5.8361\n",
      "Epoch  2 | Train 5.3900 | Val 5.8361\n",
      "Epoch  3 | Train 5.3107 | Val 5.6418\n",
      "Epoch  3 | Train 5.3107 | Val 5.6418\n",
      "Epoch  4 | Train 5.2425 | Val 5.7368\n",
      "Epoch  4 | Train 5.2425 | Val 5.7368\n",
      "Epoch  5 | Train 5.2902 | Val 6.0830\n",
      "Epoch  5 | Train 5.2902 | Val 6.0830\n",
      "Epoch  6 | Train 5.2823 | Val 5.9644\n",
      "Epoch  6 | Train 5.2823 | Val 5.9644\n",
      "Epoch  7 | Train 5.3247 | Val 5.8629\n",
      "Epoch  7 | Train 5.3247 | Val 5.8629\n",
      "Epoch  8 | Train 5.2857 | Val 5.6285\n",
      "Epoch  8 | Train 5.2857 | Val 5.6285\n",
      "Epoch  9 | Train 5.3673 | Val 5.9072\n",
      "Epoch  9 | Train 5.3673 | Val 5.9072\n",
      "Epoch 10 | Train 5.4086 | Val 5.9475\n",
      "Epoch 10 | Train 5.4086 | Val 5.9475\n",
      "Epoch 11 | Train 5.3046 | Val 5.8113\n",
      "Epoch 11 | Train 5.3046 | Val 5.8113\n",
      "Epoch 12 | Train 5.2510 | Val 5.6299\n",
      "Epoch 12 | Train 5.2510 | Val 5.6299\n",
      "Epoch 13 | Train 5.2906 | Val 5.7372\n",
      "Epoch 13 | Train 5.2906 | Val 5.7372\n",
      "Epoch 14 | Train 5.3522 | Val 5.6561\n",
      "Epoch 14 | Train 5.3522 | Val 5.6561\n",
      "Epoch 15 | Train 5.2716 | Val 5.9499\n",
      "Epoch 15 | Train 5.2716 | Val 5.9499\n",
      "Epoch 16 | Train 5.2868 | Val 5.7206\n",
      "Early stopping\n",
      "Epoch 16 | Train 5.2868 | Val 5.7206\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, epochs=25, lr=1e-3, patience=8):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best, stagnation = float('inf'), 0\n",
    "    for ep in range(epochs):\n",
    "        model.train(); tr = 0.0\n",
    "        for x in train_loader:\n",
    "            x = x.to(device)\n",
    "            _, loss = criterion(model, x)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            tr += loss.item()*x.size(0)\n",
    "        tr /= len(train_loader.dataset)\n",
    "        model.eval(); vl = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x in val_loader:\n",
    "                x = x.to(device)\n",
    "                _, loss = criterion(model, x)\n",
    "                vl += loss.item()*x.size(0)\n",
    "        vl /= len(val_loader.dataset)\n",
    "        print(f'Epoch {ep:2d} | Train {tr:.4f} | Val {vl:.4f}')\n",
    "        if vl < best:\n",
    "            best, stagnation = vl, 0\n",
    "            torch.save(model.state_dict(), 'best_cae.pth')\n",
    "        else:\n",
    "            stagnation += 1\n",
    "            if stagnation >= patience:\n",
    "                print('Early stopping'); break\n",
    "    model.load_state_dict(torch.load('best_cae.pth'))\n",
    "\n",
    "train_model(cae, train_loader, val_loader, cae_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417fdeed",
   "metadata": {},
   "source": [
    "## Variational Auto‑Encoder (VAE)\n",
    "Replacing the deterministic bottleneck with a probabilistic latent distribution, the VAE introduces a Kullback–Leibler divergence term to regularise the encoding space. Such stochasticity often enhances generalisation, contributing a 2–3 % AUC uplift on comparable anomaly‑detection benchmarks. The implementation follows a β‑VAE variant whereby the KL contribution is tempered by a tunable scalar β."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b75be19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | Train 468.1860 | Val 12.6178\n",
      "Epoch  1 | Train 7.7070 | Val 6.9750\n",
      "Epoch  1 | Train 7.7070 | Val 6.9750\n",
      "Epoch  2 | Train 6.3949 | Val 6.9810\n",
      "Epoch  2 | Train 6.3949 | Val 6.9810\n",
      "Epoch  3 | Train 6.2901 | Val 6.8110\n",
      "Epoch  3 | Train 6.2901 | Val 6.8110\n",
      "Epoch  4 | Train 6.0541 | Val 6.5985\n",
      "Epoch  4 | Train 6.0541 | Val 6.5985\n",
      "Epoch  5 | Train 5.9307 | Val 6.5630\n",
      "Epoch  5 | Train 5.9307 | Val 6.5630\n",
      "Epoch  6 | Train 5.8767 | Val 6.3504\n",
      "Epoch  6 | Train 5.8767 | Val 6.3504\n",
      "Epoch  7 | Train 5.5153 | Val 6.6736\n",
      "Epoch  7 | Train 5.5153 | Val 6.6736\n",
      "Epoch  8 | Train 5.3989 | Val 5.8275\n",
      "Epoch  8 | Train 5.3989 | Val 5.8275\n",
      "Epoch  9 | Train 5.3000 | Val 5.6857\n",
      "Epoch  9 | Train 5.3000 | Val 5.6857\n",
      "Epoch 10 | Train 5.2441 | Val 5.7929\n",
      "Epoch 10 | Train 5.2441 | Val 5.7929\n",
      "Epoch 11 | Train 5.2933 | Val 5.6961\n",
      "Epoch 11 | Train 5.2933 | Val 5.6961\n",
      "Epoch 12 | Train 5.2553 | Val 5.7278\n",
      "Epoch 12 | Train 5.2553 | Val 5.7278\n",
      "Epoch 13 | Train 5.2750 | Val 5.8718\n",
      "Epoch 13 | Train 5.2750 | Val 5.8718\n",
      "Epoch 14 | Train 5.2731 | Val 5.8206\n",
      "Epoch 14 | Train 5.2731 | Val 5.8206\n",
      "Epoch 15 | Train 5.2425 | Val 5.6561\n",
      "Epoch 15 | Train 5.2425 | Val 5.6561\n",
      "Epoch 16 | Train 5.2616 | Val 5.8073\n",
      "Epoch 16 | Train 5.2616 | Val 5.8073\n",
      "Epoch 17 | Train 5.2357 | Val 5.8869\n",
      "Epoch 17 | Train 5.2357 | Val 5.8869\n",
      "Epoch 18 | Train 5.2285 | Val 5.5946\n",
      "Epoch 18 | Train 5.2285 | Val 5.5946\n",
      "Epoch 19 | Train 5.2277 | Val 5.6002\n",
      "Epoch 19 | Train 5.2277 | Val 5.6002\n",
      "Epoch 20 | Train 5.2619 | Val 5.6023\n",
      "Epoch 20 | Train 5.2619 | Val 5.6023\n",
      "Epoch 21 | Train 5.2275 | Val 5.7127\n",
      "Epoch 21 | Train 5.2275 | Val 5.7127\n",
      "Epoch 22 | Train 5.2178 | Val 5.8777\n",
      "Epoch 22 | Train 5.2178 | Val 5.8777\n",
      "Epoch 23 | Train 5.2074 | Val 5.6683\n",
      "Epoch 23 | Train 5.2074 | Val 5.6683\n",
      "Epoch 24 | Train 5.3108 | Val 5.6663\n",
      "Epoch 24 | Train 5.3108 | Val 5.6663\n"
     ]
    }
   ],
   "source": [
    "class VAE(CAE):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__(latent_dim)\n",
    "        # Override encoder head\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.mu = nn.Linear(64, latent_dim)\n",
    "        self.logvar = nn.Linear(64, latent_dim)\n",
    "        self.dec_fc = nn.Linear(latent_dim, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.enc(x)\n",
    "        mu, logvar = self.mu(h), self.logvar(h)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        z = mu + std * torch.randn_like(std)\n",
    "        recon = self.dec(self.dec_fc(z).view(-1, 64, 1, 1))\n",
    "        return recon, mu, logvar\n",
    "\n",
    "beta = 0.001\n",
    "vae = VAE().to(device)\n",
    "\n",
    "def vae_loss(model, x):\n",
    "    recon, mu, logvar = model(x)\n",
    "    x_resized = nn.functional.adaptive_avg_pool2d(x, recon.shape[2:])\n",
    "    mse = nn.functional.mse_loss(recon, x_resized, reduction='mean')\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon, mse + beta * kld\n",
    "\n",
    "train_model(vae, train_loader, val_loader, vae_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d0963",
   "metadata": {},
   "source": [
    "## Normalizing Flow / Masked Auto‑Encoder (Optional)\n",
    "For participants equipped with ample GPU resources, this section sketches how to integrate an explicit density estimator (Normalizing Flow) or a self‑supervised Masked Auto‑Encoder for additional performance gains. Both approaches can provide calibrated likelihoods or context‑aware reconstruction signals that complement the CAE and VAE baselines. Implementation details are referenced from the `nflows` library and the AudioMAE repository and are intentionally modular for straightforward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070fd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder: define and train a RealNVP flow or import a pre‑trained AudioMAE here\n",
    "print('Implement Normalizing Flow or MAE here if hardware budget permits.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c5c5d",
   "metadata": {},
   "source": [
    "## Deep SVDD (One‑Class Classification)\n",
    "Deep Support Vector Data Description embeds inputs into a hypersphere whose radius implicitly models normal‑class variability, eschewing reconstruction altogether. Its inference cost is minimal because anomaly scoring reduces to computing Euclidean distance in latent space. A concise training loop optimises the centre and network weights jointly, yielding a lightweight model suitable for edge deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c73f24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | Loss 143.1016\n",
      "Epoch  1 | Loss 4.7594\n",
      "Epoch  1 | Loss 4.7594\n",
      "Epoch  2 | Loss 4.1252\n",
      "Epoch  2 | Loss 4.1252\n",
      "Epoch  3 | Loss 3.4950\n",
      "Epoch  3 | Loss 3.4950\n",
      "Epoch  4 | Loss 3.3660\n",
      "Epoch  4 | Loss 3.3660\n",
      "Epoch  5 | Loss 3.2244\n",
      "Epoch  5 | Loss 3.2244\n",
      "Epoch  6 | Loss 3.0544\n",
      "Epoch  6 | Loss 3.0544\n",
      "Epoch  7 | Loss 2.5931\n",
      "Epoch  7 | Loss 2.5931\n",
      "Epoch  8 | Loss 2.6089\n",
      "Epoch  8 | Loss 2.6089\n",
      "Epoch  9 | Loss 2.3354\n",
      "Epoch  9 | Loss 2.3354\n"
     ]
    }
   ],
   "source": [
    "class SVDDNet(nn.Module):\n",
    "    def __init__(self, emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        # Hitung dimensi keluaran lapisan convolutional secara dinamis\n",
    "        with torch.no_grad():\n",
    "            dummy_input = next(iter(train_loader)).to(device)\n",
    "            conv_out = self.conv(dummy_input)\n",
    "            flat_dim = conv_out.shape[1]  # Dimensi keluaran lapisan convolutional\n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(flat_dim, emb_dim)  # Sesuaikan dimensi input lapisan linear\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Inisialisasi model dan optimizer\n",
    "svdd = SVDDNet().to(device)\n",
    "optimizer = torch.optim.Adam(svdd.parameters(), lr=1e-4)\n",
    "center = torch.zeros(128, device=device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    svdd.train()\n",
    "    epoch_loss = 0.0\n",
    "    for x in train_loader:\n",
    "        x = x.to(device)\n",
    "        emb = svdd(x)\n",
    "        if epoch == 0:\n",
    "            center = 0.9 * center + 0.1 * emb.mean(0).detach()\n",
    "        dist = ((emb - center) ** 2).sum(1)\n",
    "        loss = dist.mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * x.size(0)\n",
    "    print(f'Epoch {epoch:2d} | Loss {epoch_loss / len(train_loader.dataset):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e46674",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Consistent with DCASE conventions, performance is quantified via the Area Under the Receiver Operating Characteristic Curve (AUC‑ROC), a threshold‑independent ranking measure. Computed on a held‑out validation set containing both normal and anomalous recordings, this scalar facilitates objective comparison across model families. Bootstrap resampling can optionally provide confidence intervals to assess statistical reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b02c3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_error(model, path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        feat = torch.from_numpy(extract_logmel(path)).unsqueeze(0).to(device)\n",
    "        recon = model(feat)\n",
    "        return torch.mean((recon - feat)**2).item()\n",
    "\n",
    "# Placeholder for real validation labels\n",
    "# val_labels = [...]\n",
    "# val_scores = [reconstruction_error(cae, f) for f in val_files]\n",
    "# print('AUC:', metrics.roc_auc_score(val_labels, val_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650c2ab",
   "metadata": {},
   "source": [
    "## Submission File Generation\n",
    "To conform to the official scoring server, anomaly scores are collated into a header‑less CSV containing `filename` and `anomaly_score` columns. Consistent filename ordering is crucial to prevent misalignment between the submission file and the hidden evaluation labels. The function below accommodates any scoring model by injecting a callable that maps file paths to scalar scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8819e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1101 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x1248 and 39936x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\u001b[38;5;241m.\u001b[39mto_csv(out, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubmission saved to\u001b[39m\u001b[38;5;124m'\u001b[39m, out)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mwrite_submission\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstruction_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmission-new.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m, in \u001b[0;36mwrite_submission\u001b[0;34m(file_list, scoring_fn, out)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrite_submission\u001b[39m(file_list, scoring_fn, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     rows \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m: f\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomaly_score\u001b[39m\u001b[38;5;124m'\u001b[39m: scoring_fn(f)} \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tqdm(file_list)]\n\u001b[1;32m      4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\u001b[38;5;241m.\u001b[39mto_csv(out, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubmission saved to\u001b[39m\u001b[38;5;124m'\u001b[39m, out)\n",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrite_submission\u001b[39m(file_list, scoring_fn, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     rows \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m: f\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomaly_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mscoring_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m} \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tqdm(file_list)]\n\u001b[1;32m      4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\u001b[38;5;241m.\u001b[39mto_csv(out, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubmission saved to\u001b[39m\u001b[38;5;124m'\u001b[39m, out)\n",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m      4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\u001b[38;5;241m.\u001b[39mto_csv(out, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubmission saved to\u001b[39m\u001b[38;5;124m'\u001b[39m, out)\n\u001b[1;32m      8\u001b[0m write_submission(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28msorted\u001b[39m((DATA_DIR\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m f: \u001b[43mreconstruction_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     11\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission-new.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m, in \u001b[0;36mreconstruction_error\u001b[0;34m(model, path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(extract_logmel(path))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m     recon \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean((recon \u001b[38;5;241m-\u001b[39m feat)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m, in \u001b[0;36mSVDDNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x1248 and 39936x128)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def write_submission(file_list, scoring_fn, out='submission.csv'):\n",
    "    rows = [{'filename': f.name, 'anomaly_score': scoring_fn(f)} for f in tqdm(file_list)]\n",
    "    pd.DataFrame(rows).to_csv(out, index=False, header=False)\n",
    "    print('Submission saved to', out)\n",
    "\n",
    "\n",
    "write_submission(\n",
    "    sorted((DATA_DIR/'test').rglob('*.wav')),\n",
    "    lambda f: reconstruction_error(svdd, f),\n",
    "    out='submission-new.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb623d66",
   "metadata": {},
   "source": [
    "## Conclusion & Future Work\n",
    "This notebook operationalises four complementary unsupervised anomaly‑detection paradigms, thus satisfying the methodology requirements of the AML 2025 Slide‑Rail lab. Students are encouraged to fine‑tune hyper‑parameters, integrate data augmentation, or ensemble model outputs to elevate empirical performance. Moreover, cross‑referencing the GitHub repositories may inspire nuanced architectural enhancements or novel evaluation protocols."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
