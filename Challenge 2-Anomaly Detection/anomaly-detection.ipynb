{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f938add",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook constitutes a reproducible baseline for the Slide‑Rail Acoustic‑Anomaly Detection task of the AML 2025 course.\n",
    "It chronicles the complete experimental workflow, spanning data acquisition, signal processing, model construction, and result submission.\n",
    "The structure adheres to scholarly conventions to facilitate critical inspection and future extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a82d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e17566",
   "metadata": {},
   "source": [
    "## Environment and Data Acquisition\n",
    "This section ensures that the required libraries are installed and retrieves the official DCASE Slide‑Rail dataset via the Kaggle API.\n",
    "Users who already possess a local copy may deactivate the download block by setting the `DOWNLOAD_DATA` flag to `False`.\n",
    "All paths are resolved relative to `DATA_DIR`, promoting portability across heterogeneous computing environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c792a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data acquisition setup\n",
    "DOWNLOAD_DATA = False  # set to True on first run\n",
    "DATA_DIR = Path(\"./dataset\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if DOWNLOAD_DATA:\n",
    "    kaggle_url = \"dcase-task2-slidRail-2023.zip\"  # placeholder; update with actual Kaggle file name\n",
    "    if not (RAW_DIR / kaggle_url).exists():\n",
    "        subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"dcase-repo/dcase2023-task2\", \"-p\", str(RAW_DIR)])\n",
    "    with zipfile.ZipFile(RAW_DIR / kaggle_url, \"r\") as zf:\n",
    "        zf.extractall(RAW_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0efed",
   "metadata": {},
   "source": [
    "## Acoustic Feature Extraction\n",
    "Log‑Mel spectrograms are employed owing to their proven efficacy in representing perceptual frequency content for machine‑condition sounds.\n",
    "The helper function `extract_logmels` converts each waveform into a time–frequency representation that serves as input to both deep and classical models.\n",
    "Parameters follow the DCASE baseline configuration to enable fair comparison with published results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84a3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function\n",
    "def extract_logmels(wav_path, sr=16000, n_fft=1024, hop_length=512, n_mels=64):\n",
    "    y, sr = librosa.load(wav_path, sr=sr, mono=True)\n",
    "    mel = librosa.feature.melspectrogram(y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    logmel = librosa.power_to_db(mel).astype(np.float32)\n",
    "    return logmel.T  # shape (time, n_mels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4098d22",
   "metadata": {},
   "source": [
    "## Convolutional Auto‑Encoder Baseline\n",
    "The convolutional auto‑encoder (CAE) is adopted as a reconstruction‑based anomaly detector that minimizes the mean‑squared error on normal signals.\n",
    "During inference, samples exhibiting elevated reconstruction loss are hypothesised as anomalous, yielding a scalar anomaly score.\n",
    "The architecture remains intentionally lightweight to accommodate limited GPU resources typically available in academic settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155cc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Autoencoder (CAE) model\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self, n_mels=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# Dummy training loop placeholder\n",
    "def train_cae(model, dataloader, epochs=20, lr=1e-3):\n",
    "    model.train()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    crit = nn.MSELoss()\n",
    "    for ep in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for xb in dataloader:\n",
    "            xb = xb.to(next(model.parameters()).device)\n",
    "            recon = model(xb)\n",
    "            loss = crit(recon, xb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {ep+1}/{epochs} - loss: {epoch_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d7f91",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model Baseline\n",
    "As a classical point of reference, a Gaussian Mixture Model (GMM) estimates the distribution of normal MFCC vectors by maximum‑likelihood via the Expectation‑Maximization algorithm.\n",
    "Samples with low log‑likelihood under the trained density are deemed anomalous, enabling a direct comparison with reconstruction‑based deep models.\n",
    "Although simplistic, the GMM continues to serve as a competitive non‑neural baseline in the DCASE evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc9bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Mixture Model (GMM) setup\n",
    "def extract_mfcc(wav_path, sr=16000, n_mfcc=20, hop_length=512):\n",
    "    y, sr = librosa.load(wav_path, sr=sr, mono=True)\n",
    "    mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length)\n",
    "    return mfcc.T  # shape (time, n_mfcc)\n",
    "\n",
    "class GMMDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        return extract_mfcc(self.file_paths[idx])\n",
    "\n",
    "# Placeholder fitting\n",
    "def fit_gmm(train_files, n_components=16):\n",
    "    feats = np.vstack([extract_mfcc(f) for f in train_files])\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type='diag', max_iter=100)\n",
    "    gmm.fit(feats)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676bc2a5",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "The Area Under the Receiver Operating Characteristic Curve (AUC‑ROC) is adopted as the principal metric, consistent with prior DCASE tasks.\n",
    "It offers a threshold‑independent assessment of ranking quality, thereby accommodating heterogeneous operating scenarios.\n",
    "Confidence intervals may be approximated via bootstrap resampling to gauge statistical significance among competing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "616af73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(scores, labels):\n",
    "    auc = metrics.roc_auc_score(labels, scores)\n",
    "    print(f\"AUC‑ROC: {auc:.3f}\")\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a7918",
   "metadata": {},
   "source": [
    "## Submission File Generation\n",
    "The final cell assembles the anomaly scores for the evaluation subset into a comma‑separated values (CSV) file, conforming to the challenge submission format.\n",
    "The CSV comprises two columns—`filename` and `score`—without a header, aligning with the official evaluation script.\n",
    "Ensure deterministic ordering of filenames to preclude inadvertent misalignment between scores and audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb808330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission file generation\n",
    "def write_submission(filenames, scores, out_path=\"submission.csv\"):\n",
    "    df = pd.DataFrame({\"filename\": filenames, \"score\": scores})\n",
    "    df.to_csv(out_path, index=False, header=False)\n",
    "    print(f\"Submission saved to {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
