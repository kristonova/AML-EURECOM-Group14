{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# Sentiment Analysis Notebook\n",
        "This notebook performs sentiment analysis using a logistic regression model with TF-IDF vectorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /Users/mymac/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /Users/mymac/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 1. Load and Explore Data\n",
        "Load the training and test datasets, and display basic information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (24732, 4)\n",
            "       textID                                               text  \\\n",
            "0  28ac06f416                        good luck with your auction   \n",
            "1  92098cf9a7  Hmm..You can`t judge a book by looking at its ...   \n",
            "2  7858ff28f2   Hello, yourself. Enjoy London. Watch out for ...   \n",
            "3  b0c9c67f32         We can`t even call you from belgium  sucks   \n",
            "4  7b36e9e7a5                                 not so good mood..   \n",
            "\n",
            "                                       selected_text sentiment  \n",
            "0                        good luck with your auction  positive  \n",
            "1  Hmm..You can`t judge a book by looking at its ...   neutral  \n",
            "2                                    They`re mental.  negative  \n",
            "3                                            m  suck  negative  \n",
            "4                                 not so good mood..  negative  \n",
            "\n",
            "Test shape: (2748, 3)\n",
            "       textID                                               text  \\\n",
            "0  102f98e5e2                          Happy Mother`s Day hahaha   \n",
            "1  033b399113  Sorry for the triple twitter post, was having ...   \n",
            "2  c125e29be2           thats much better than the flu syndrome!   \n",
            "3  b91e2b0679                            Aww I have a tummy ache   \n",
            "4  1a46141274   hey chocolate chips is good.  i want a snack ...   \n",
            "\n",
            "                                       selected_text  \n",
            "0                                 Happy Mother`s Day  \n",
            "1  Sorry for the triple twitter post, was having ...  \n",
            "2                                  thats much better  \n",
            "3                                         tummy ache  \n",
            "4                                              good.  \n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv(\"dataset/train.csv\")\n",
        "test_df = pd.read_csv(\"dataset/test.csv\")\n",
        "\n",
        "# Display dataset information\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(train_df.head())\n",
        "print(\"\\nTest shape:\", test_df.shape)\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 2. Preprocess Data\n",
        "Define a function to clean and preprocess the text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "X = train_df['text']\n",
        "y = train_df['sentiment']\n",
        "X = X.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 3. Split Data\n",
        "Split the training data into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 4. Build and Train Model\n",
        "Create a pipeline with TF-IDF vectorization and logistic regression, and perform hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        }
      ],
      "source": [
        "pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(\n",
        "        lowercase=True,\n",
        "        stop_words=\"english\",\n",
        "        ngram_range=(1, 2),\n",
        "        max_features=5000\n",
        "    )),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        C=1.0,\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
        "    \"tfidf__max_features\": [5000, 10000],\n",
        "    \"clf__C\": [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=3, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Use the best model\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 5. Evaluate Model\n",
        "Evaluate the model on the validation set using the Macro F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "F1 macro after tuning: 0.6910\n",
            "Best parameters: {'clf__C': 1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "y_val_pred = best_model.predict(X_val)\n",
        "f1_macro = f1_score(y_val, y_val_pred, average='macro')\n",
        "print(f\"\\nF1 macro after tuning: {f1_macro:.4f}\")\n",
        "print(\"Best parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 6. Predict on Test Data\n",
        "Use the trained model to predict sentiment for the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example of 10 sentiment predictions for test data:\n",
            "['positive' 'negative' 'positive' 'negative' 'positive' 'negative'\n",
            " 'neutral' 'negative' 'positive' 'neutral']\n"
          ]
        }
      ],
      "source": [
        "X_test = test_df['text'].apply(preprocess_text)\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"\\nExample of 10 sentiment predictions for test data:\")\n",
        "print(test_predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 7. Save Predictions\n",
        "Save the predictions to a CSV file for submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "File 'my_submission.csv' has been saved.\n"
          ]
        }
      ],
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    'textID': test_df['textID'],\n",
        "    'text': test_df['text'],\n",
        "    'selected_text': test_df['selected_text'],\n",
        "    'predicted_sentiment': test_predictions\n",
        "})\n",
        "\n",
        "submission_df.to_csv(\"my_submission.csv\", index=False)\n",
        "print(\"\\nFile 'my_submission.csv' has been saved.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
